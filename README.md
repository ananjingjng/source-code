Abstract:Road traffic detection is a crucial technology for autonomous driving, enhancing driving safety through the perception of traffic-related objects. Traditional vision-based object detection methods often encounter challenges under complex road conditions and adverse visual environments. To address these challenges, this paper proposes a multimodal object detection method, EAD-PFNet, which integrates pixel-level fusion and multi-scale feature enhancement strategies. Specifically, a pixel-level fusion module is introduced at the input stage of the network to combine infrared and visible images, significantly improving detection performance in low-visibility conditions. Additionally, an Efficient Multi-scale Attention module is proposed to enhance inter-feature relationships through cross-dimensional interactions, thereby improving the model's accuracy and robustness. To further enhance the representation capability of multi-scale features, a dilated residual module is employed to optimize the feature extraction process
